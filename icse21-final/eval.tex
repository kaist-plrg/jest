\section{Evaluation}\label{sec:eval}

\begin{figure*}[t]
  \centering
  \begin{subfigure}[t]{0.48\textwidth}
    \includegraphics[width=\textwidth]{img/stmt-coverage}
    \caption{Statement coverage}
    \label{fig:stmt-coverage}
  \end{subfigure}
  \quad
  \begin{subfigure}[t]{0.48\textwidth}
    \includegraphics[width=\textwidth]{img/branch-coverage}
    \caption{Branch coverage}
    \label{fig:branch-coverage}
  \end{subfigure}
  \caption{The semantics coverage changes during the test generation phase}
  \label{fig:sem-coverage}
  \vspace*{-1em}
\end{figure*}

To evaluate $\tool$ that performs $N$+1-version differential testing of JavaScript
engines and its specification, we applied the tool to four JavaScript engines that
fully support modern JavaScript features and the latest specification,
ECMAScript 2020 (ES11, 2020).  Our experiments use the following four JavaScript
engines, all of which support ES11:
\begin{itemize}
  \item \textbf{V8(v8.5)\footnote{https://v8.dev/}:} An open-source high-performance engine
    for JavaScript and WebAssembly developed by Google~\cite{v8}
  \item \textbf{GraalJS(v20.1.0)\footnote{https://github.com/graalvm/graaljs\#current-status}:} A JavaScript implementation built on
    GraalVM~\cite{graaljs}, which is a Java Virtual Machine (JVM) based on
    HotSpot/OpenJDK developed by Oracle
  \item \textbf{QuickJS(2020-04-12)\footnote{https://bellard.org/quickjs/}:} A small and embedded JavaScript engine developed by
    Fabrice Bellard and Charlie Gordon~\cite{qjs}
  \item \textbf{Moddable XS(v10.3.0)\footnote{https://blog.moddable.com/blog/xs10/}:} A JavaScript engine at the center of the Moddable
    SDK~\cite{xs}, which is a combination of development tools and runtime
    software to create applications for micro-controllers
\end{itemize}
To extract a mechanized specification from ECMAScript, we utilize the tool
$\jiset$, which is a JavaScript IR-based semantics extraction
toolchain, to automatically generate a JavaScript interpreter from ECMAScript.
To focus on the core semantics of JavaScript, we consider only the semantics of strict mode
JavaScript code that pass syntax checking including the EarlyError rules.  To
filter out JavaScript code that are not strict or fail syntax checking,
we utilize the syntax checker of the most reliable JavaScript engine, V8.
We performed our experiments on a machine equipped with 4.0GHz Intel(R) Core(TM)
i7-6700k and 32GB of RAM (Samsung DDR4 2133MHz 8GB*4).  We evaluated $\tool$
with the following four research questions:
\begin{itemize}
\item {\bf RQ1 (Coverage of Generated Tests)} Is the semantics
coverage of the tests generated by $\tool$ comparable to that of Test262,
the official conformance test suite for ECMAScript, which is manually written?
\item {\bf RQ2 (Accuracy of Bug Localization)} Does $\tool$ localize bug locations
accurately?
\item {\bf RQ3 (Bug Detection in JavaScript Engines)} How many
bugs of four JavaScript engines does $\tool$ detect?
\item {\bf RQ4 (Bug Detection in ECMAScript)} How many
bugs of ES11 does $\tool$ detect?
\end{itemize}


\subsection{Coverage of Generated Tests}

$\tool$ generates the seed programs via \mytextsf{Seed Synthesizer},
which synthesizes 1,125 JavaScript programs in about 10
seconds and covers 97.78\% (397/406) of reachable 
alternatives in the syntax productions of ES11.
Among them, we filtered out 602 programs that do not increase
the semantics coverage and started the mutation iteration with 523 programs.
Figure~\ref{fig:sem-coverage} shows the change of
semantics coverage of the program pool during the iterative process in 100 hours.
The left and right graphs present the statement and branch coverages,
respectively, and the top red line denotes the coverage of Test262.
We generated conformance tests two times before and after fixing bugs detected
by $\tool$ because the specification bugs affected the semantics coverage.
In each graph, dark gray X marks and blue O marks denote the semantics coverage
of generated tests before and after fixing bugs.
The semantics that we target in ES11 consists of 1,550 algorithms with 24,495
statements and 9,596 branches.
For the statement coverage, Test262 covers 22,440 (91.61\%) statements.
The initial program pool covers 12,768 (52.12\%) statements
and the final program pool covers 21,230 (86.67\%) and
21,482 (87.70\%) statements before and after fixing bugs, respectively.
For the branch coverage, Test262 covers 7,956 (82.91\%) branches.
The initial program pool covers 3,987 (41.55\%) branches
and the final program pool covers 7,480 (77.95\%) and
7,514 (78.30\%) branches before and after fixing bugs, respectively.

\begin{table}
  \caption{Number of generated programs and covered branches of mutation methods}
  \label{table:mutation-method}
  \vspace*{-1em}
  \small
  \[
    \begin{array}{l?r|r}
      \telembf{c?}{Mutation Method}      & \telembf{c|}{Program}  & \telembf{c}{Branch (Avg.)}\\\toprule\\[-1.4em]
      \text{Nearest Syntax Tree Mutation} & 459                   & 1,230 (2.68)\\\hline
      \text{Random Mutation}              & 337                   & 1,153 (3.42)\\\hline
      \text{Statement Insertion}          & 209                   & 650   (3.11)\\\hline
      \text{Object Substitution}          & 169                   & 491   (2.91)\\\hline
      \text{String Substitution}          & 3                     & 3     (1.00)\\\hline
      \hline
      \telembf{c?}{Total}                 & 1,177                 & 3,527 (3.00)\\
    \end{array}
  \]
  \vspace*{-3em}
\end{table}

Table~\ref{table:mutation-method} shows the number of synthesized programs and covered
branches for each mutation method during the test generation phase.  In total,
$\tool$ successfully synthesize 1,177 new programs that cover 3,527
more branches than the initial program pool.  Among five mutation methods, the
nearest syntax tree mutation is the most contributed method (459
programs and 1,230 covered branches) and the least one is the string
substitution (3 programs and 3 covered branches).  On average,
3.00 branches are covered by a new program.

Finally, $\tool$ generates 1,700 JavaScript programs and their average number of
lines is 2.01.  After injecting assertions, their average number of lines
becomes 8.45.  Compared to Test262, the number of generated tests are much
smaller and their number of lines are also shorter than those of tests in
Test262.  Test262 provides 16,251 tests for the same range of semantics and
their average number of lines is 49.67.


\subsection{Accuracy of Bug Localization}

\begin{figure}[t]
  \centering
  \includegraphics[width=0.48\textwidth]{img/localize}
  \caption{Ranks of algorithms that caused the bugs detected by $\tool$}
  \label{fig:localize}
  \vspace*{-1em}
\end{figure}

\setcounter{table}{2}
\begin{table*}[t]
  \centering
  \caption{Specification bugs in ECMAScript 2020 (ES11) detected by $\tool$}
  \label{table:spec-bug}
  \vspace*{-.5em}
  \small
  \begin{tabular}{@{}c@{~}?c|@{~}c@{~}|l|c|c|@{~}c@{~}|@{~}c@{~}|@{~}r@{}}
    \telembf{@{}c?}{\bf Name} &
    \telembf{c}{\bf Feature} &
    \telembf{@{}c@{~}}{\bf \#} &
    \telembf{c}{\bf Description} &
    \telembf{@{~}c@{~}}{\bf Assertion} &
    \telembf{@{~}c}{\bf Known} &
    \telembf{@{}c}{\bf Created} &
    \telembf{@{}c}{\bf Resolved} &
    \telembf{@{}c@{~}}{\bf Existed} \\\toprule\\[-1.4em]

    ES11-1 &
    \text{Function} &
    12 &
    \makecell[l]{Wrong order between property keys for functions} &
    \mytextsf{Key} &
    O &
    2019-02-07 &
    2020-04-11 &
    429 days \\\hline

    ES11-2 &
    \text{Function} &
    8 &
    \makecell[l]{Missing property \code{name} for anonymous functions} &
    \mytextsf{Key} &
    O &
    2015-06-01 &
    2020-04-11 &
    1,776 days \\\hline

    ES11-3 &
    \text{Loop} &
    1 &
    \makecell[l]{Returning iterator objects instead of iterator records\\
      in \textbf{ForIn/OfHeadEvaluation} for \code{for-in} loops} &
    \mytextsf{Exc} &
    O &
    2017-10-17 &
    2020-04-30 &
    926 days \\\hline

    ES11-4 &
    \text{Expression} &
    4 &
    \makecell[l]{Using the wrong variable \code{oldvalue} instead of\\
      \code{oldValue} in \textbf{Evaluation} of \textit{UpdateExpression}} &
    \mytextsf{Abort} &
    O &
    2019-09-27 &
    2020-04-23 &
    209 days \\\hline

    ES11-5 &
    \text{Expression} &
    1 &
    \makecell[l]{Unhandling abrupt completion\\
      in \textbf{Abstract Equality Comparison}} &
    \mytextsf{Exc} &
    O &
    2015-06-01 &
    2020-04-28 &
    1,793 days \\\hline

    ES11-6 &
    \text{Object} &
    1 &
    \makecell[l]{Unhandling abrupt completion in \textbf{Evaluation} of\\
      \textit{PropertyDefinition} for object literals} &
    \mytextsf{Exc} &
    X &
    2019-02-07 &
    TBD &
    TBD
  \end{tabular}
  \vspace*{-0.5em}
\end{table*}

\setcounter{table}{1}
\begin{table}
  \caption{The number of engine bugs detected by $\tool$}
  \label{table:engine-bug}
  \vspace*{-1em}
  \small
  \[
    \begin{array}{l?r|r|r|r|r|r|r?r}
      \telembf{@{}c@{~}?}{Engines} &
      \telemsf{@{~}c@{~}|}{Exc} &
      \telemsf{@{~}c@{~}|}{Abort} &
      \telemsf{@{~}c@{~}|}{Var} &
      \telemsf{@{~}c@{~}|}{Obj} &
      \telemsf{@{~}c@{~}|}{Desc} &
      \telemsf{@{~}c@{~}|}{Key} &
      \telemsf{@{~}c@{~}?}{In} &
      \telembf{@{~}c@{}}{Total}\\\toprule\\[-1.4em]

      \text{V8}           & 0   & 0 & 0 & 0 & 0 & 2   & 0 & 2\\\hline
      \text{GraalJS}      & 6   & 0 & 0 & 0 & 2 & 8   & 0 & 16\\\hline
      \text{QuickJS}      & 3   & 0 & 1 & 0 & 0 & 2   & 0 & 6\\\hline
      \text{Moddable XS}  & 12  & 0 & 0 & 0 & 3 & 5   & 0 & 20\\\hline
      \hline
      \telembf{c?}{Total} & 21  & 0 & 1 & 0 & 5 & 17  & 0 & 44\\
    \end{array}
  \]
  \vspace*{-1.5em}
\end{table}

To detect more bugs using more diverse programs,
we repeated the conformance test generation phase for ten times.
We executed the generated conformance tests on four JavaScript engines
to find bugs in the engines and the specification.
After inferring locations of the bugs in the engines or the specification
based on the majority of the execution results, we manually checked
whether the bugs are indeed in the engines or the specification. 
The following table shows that our method works well:

\begin{table}[H]
  \centering
  \vspace*{-1em}
  \small
  \[
    \begin{array}{l?r|r|r|r?r?r}
      \telembf{c?}{\# Failed Engines} &
      \telembf{c}{1} &
      \telembf{c}{2} &
      \telembf{c}{3} &
      \telembf{c?}{4} &
      \telembf{c?}{Total} &
      \telembf{c}{Average} \\\toprule\\[-1.4em]

      \text{Engine Bugs}        & 38  & 6   & 0   & 0   & 44  & 1.14\\\hline
      \text{Specification Bugs} & 0   & 0   & 10  & 17  & 27  & 3.63\\
    \end{array}
  \]
  \vspace*{-1em}
\end{table}

\noindent
For engine bugs, the average number of engine failures is 1.14
while the average number of failed engines for specification bugs is 3.63.
As we expected, when most engines fail for a test, the specification
may have a bug.

Based on the results of conformance tests on four JavaScript engines, we localized
the specification or engine bugs on the \emph{semantics} of ES11.
Among 71 bugs, we excluded 7 syntax bugs and localized only 64 semantics bugs.
Figure~\ref{fig:localize} shows the ranks of algorithms that caused the semantics bugs.
The average rank is 3.19, and 82.8\% of the algorithms causing the
bugs are ranked less than 5, 93.8\% less than 10, and 98.4\% less than 15.
Note that the location of one bug is ranked 21 because of the limitation of SBFL;
its localization accuracy becomes low for a small number of failed test cases.



\subsection{Bug Detection in JavaScript Engines}
From four JavaScript engines, $\tool$ detected 44 bugs:
2 from V8, 16 from GraalJS,
6 from QuickJS, and 20 from Moddable XS.
Table~\ref{table:engine-bug} presents how many bugs for each assertion are detected
for each engine.  We injected seven kinds of assertions: exceptions
(\mytextsf{Exc}), aborts (\mytextsf{Abort}), variable values (\mytextsf{Var}), object
values (\mytextsf{Obj}), object properties (\mytextsf{Desc}), property keys
(\mytextsf{Key}), and internal methods and slots (\mytextsf{In}).
The effectiveness of bug finding is different for different assertions.
The \mytextsf{Exc} and \mytextsf{Key} assertions detected
engine bugs the most; out of 44 bugs, the former detected 21 bugs
and the latter detected 17 bugs.
\mytextsf{Desc} and \mytextsf{Var} detected 5 and 1 bugs, respectively, but the
other assertions did not detect any engine bugs.

The most reliable JavaScript engine is V8 because $\tool$ found only two bugs and
the bugs are due to specification bugs in ES11.  Because V8 strictly follows the
semantics of functions described in ES11, it also implemented wrong semantics
that led to ES11-1 and ES11-2 listed in Table~\ref{table:spec-bug}.
The V8 team confirmed the bugs and fixed them.

We detected 16 engine bugs in GraalJS and one of them caused an engine
crash.  When we apply the prefix increment operator for \code{undefined}
as \code{++undefined}, GraalJS throws \code{java.lang.IllegalStateException}.
Because it crashes the engine, developers even cannot catch the exception as follows:
\begin{lstlisting}[style=myJSstyle]
    try { ++undefined; } catch(e) { }
\end{lstlisting}
The GraalJS team has been fixing the bugs we reported and
asked whether we plan to publish the conformance test suite,
because the tests generated by $\tool$ detected many semantics bugs that
were not detected by other conformance tests:
\emph{``Right now, we are running Test262 and the V8 and Nashorn
unit test suites in our CI for every change, it might make sense to
add your suite as well.''}

In QuickJS, $\tool$ detected 6 engine bugs, most of which are due to corner cases of
the function semantics.  For example, the following code should throw
a \code{ReferenceError} exception:
\begin{lstlisting}[style=myJSstyle]
    function f (... { x = x }) { return x; } f()
\end{lstlisting}
because the variable \code{x} is not yet initialized when it tries to
read the right-hand side of \code{x = x}.
However, since QuickJS assumes that the initial value of \code{x} is
\code{undefined}, the function call \code{f()} returns \code{undefined}.
The QuickJS team confirmed our bug reports and it has been fixing the bugs.

$\tool$ found the most bugs in Moddable XS; it detected 20 bugs for various
language features such as optional chains, \code{Number.prototype.toString},
iterators of \code{Map} and \code{Set}, and complex assignment patterns.
Among them, optional chains are newly introduced in ES11, which shows that
our approach is applicable to finding bugs in new language features.
We reported all the bugs found, and the Moddable XS team has been
fixing them.  They showed interests in using our test suite:
\emph{``As you know, it is difficult to verify changes because the language specification
is so big. Test262, as great a resource as it is, is not definitive.''}

\subsection{Bug Detection in ECMAScript}
From the latest ECMAScript ES11, $\tool$ detected 27 specification bugs.
Table~\ref{table:spec-bug} summarizes the bugs categorized by their root causes.
Among them, five categories (ES11-1 to ES11-5) were already reported and fixed in the current
draft of the next ECMAScript but ES11-6 was never reported before.
We reported it to TC39; they confirmed it and they will
fix it in the next version, ECMAScript 2021 (ES12).

ES11-1 contains 12 bugs; it is due to a wrong order between property keys of all kinds of
function values such as \code{async} and generator functions, arrow functions, and classes.
For example, if we define a class declaration with a name \code{A}
(\code{class A \{\}}), three properties are defined in the function
stored in the variable \code{A}: \code{length} with a number value \code{0},
\code{prototype} with an object, and \code{name} with a string \code{"A"}.
The problem is the different order of their keys because of
the wrong order of their creation.
From ECMAScript 2015 (ES6), the order between property keys is no
more implementation-dependent but it is related to the creation order of properties.
While the order of property keys in the class \code{A} should be \code{[length, prototype, name]}
according to the semantics of ES11, the order is \code{[length, name, prototype]}
in three engines except V8.  We found that it was already reported as a specification bug;
we reported it to V8 and they fixed it.
This bug was created on February 7, 2019 and TC39 fixed it on April 11, 2020;
the bug lasted for 429 days.

ES11-2 contains 8 bugs that are due to the missing property
\code{name} of anonymous functions.  Until ES5.1, anonymous functions, such as an identity arrow
function \code{x => x}, had their own property \code{name} with an empty string \code{""}.
While ES6 removed the \code{name} property from anonymous functions,
three engines except V8 still create the \code{name} property in anonymous functions.
We also found that it was reported as a specification bug and reported it
to V8, and it will be fixed in V8.

The bug in ES11-3 comes from the misunderstanding of the term ``iterator
object'' and ``iterator record''.  The algorithm \textbf{ForIn/OfHeadEvaluation}
should return an iterator record, which is an implicit record containing only internal slots.
However, In ES11, it returns an iterator object, which is a
JavaScript object with some properties related to iteration.
It causes a \code{TypeError} exception when executing the code \code{for(var x in \{\});} according to
ES11 but all engines execute the code normally without any exceptions.
This bug was resolved by TC39 on April 30, 2020.

ES11-4 contains four bugs caused by a typo for the variable in the
semantics of four different update expressions: \code{x++}, \code{x--},
\code{++x}, and \code{--x}.  In each \textbf{Evaluation} of four kinds of
\textit{UpdateExpression}, there exists a typo \code{oldvalue} in step 3
instead of \code{oldValue} declared in step 2.  $\tool$ could not execute
the code \code{x++} using the semantics of ES11 because of the typo.
For this case, we directly pass the code to \mytextsf{Bug Localizer} to test whether the
code is executable in real-world engines and to localize the bug.
Of course, four JavaScript engines executed the update expressions without any issues
and this bug was resolved by TC39 on April 23, 2020.

Two bugs in ES11-5 and ES11-6 are caused by unhandling of abrupt completions in
abstract equality comparison and property definitions of object literals, respectively.
The bug in ES11-5 was confirmed by TC39 and was fixed on April 28, 2020.
The bug in ES11-6 was a genuine one, and we reported it and received a confirmation
from TC39 on August 18, 2020. The bug will be fixed in the next version, ES12.
% from TC39 on \inred{X}; the bug lasted for \inred{X} days.
